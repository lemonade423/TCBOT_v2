import streamlit as st
import os
import zipfile
import tempfile
import pandas as pd
import requests

# âœ… OpenRouter API KEY (ë³´ì•ˆ ì£¼ì˜!)
API_KEY = "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"

st.set_page_config(page_title="TC-Bot v3", layout="wide")
st.title("ğŸ§ª TC-Bot v3: í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìë™ ìƒì„±ê¸°")

# =========================
# âœ… [ìˆ˜ì •] ìƒ˜í”Œ ZIP íŒŒì¼ ë¡œë“œ í•¨ìˆ˜ (ì—…ë¡œë“œëœ ì‹¤ì œ zip ì‚¬ìš©)
# =========================
def _load_sample_zip() -> bytes:
    sample_path = "/mnt/data/tc-bot-sample-code.zip"  # ì—…ë¡œë“œëœ ê²½ë¡œ ê³ ì •
    with open(sample_path, "rb") as f:
        return f.read()

# âœ… ì‚¬ì´ë“œë°” ì…ë ¥
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    model = st.selectbox("ğŸ¤– ì‚¬ìš©í•  LLM ëª¨ë¸", ["qwen/qwen-max", "mistral"])
    role = st.selectbox("ğŸ‘¤ QA ì—­í• ", ["ê¸°ëŠ¥ QA", "ë³´ì•ˆ QA", "ì„±ëŠ¥ QA"])

    # =========================
    # âœ… [ìˆ˜ì •] ìƒ˜í”Œ ZIP ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    # =========================
    st.markdown("---")
    st.subheader("ğŸ“¦ ìƒ˜í”Œ ZIP")
    st.caption("ì—…ë¡œë“œìš© ì˜ˆì œ ZIP íŒŒì¼ì´ í•„ìš”í•˜ë©´ ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë°›ìœ¼ì„¸ìš”.")
    st.download_button(
        "â¬‡ï¸ ìƒ˜í”Œì½”ë“œ ZIP ë‹¤ìš´ë¡œë“œ",
        data=_load_sample_zip(),
        file_name="tc-bot-sample-code.zip",
        mime="application/zip",
        help="ì—…ë¡œë“œëœ ì‹¤ì œ ìƒ˜í”Œ ZIP íŒŒì¼ì„ ê·¸ëŒ€ë¡œ ë‹¤ìš´ë¡œë“œ"
    )

# âœ… ì„¸ì…˜ ì´ˆê¸°í™”
if "last_uploaded_file" not in st.session_state:
    st.session_state.last_uploaded_file = None
if "last_model" not in st.session_state:
    st.session_state.last_model = None
if "last_role" not in st.session_state:
    st.session_state.last_role = None
if "llm_result" not in st.session_state:
    st.session_state.llm_result = None
if "parsed_df" not in st.session_state:
    st.session_state.parsed_df = None

uploaded_file = st.file_uploader("ğŸ“‚ ì†ŒìŠ¤ì½”ë“œ zip íŒŒì¼ ì—…ë¡œë“œ", type=["zip"])


def need_llm_call(uploaded_file, model, role):
    # ì´ì „ ì„¸ì…˜ ìƒíƒœì™€ ë¹„êµ
    return (uploaded_file is not None
            and (st.session_state.last_uploaded_file != uploaded_file.name
                 or st.session_state.last_model != model
                 or st.session_state.last_role != role))


# âœ… LLM í˜¸ì¶œ ì¡°ê±´ í™•ì¸
if uploaded_file and need_llm_call(uploaded_file, model, role):
    preview_box = st.empty()
    step_status = st.empty()

    with st.spinner("ğŸ” LLM í˜¸ì¶œ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):
        with tempfile.TemporaryDirectory() as tmpdir:
            zip_path = os.path.join(tmpdir, uploaded_file.name)
            with open(zip_path, "wb") as f:
                f.write(uploaded_file.read())

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(tmpdir)

            full_code = ""
            file_list = []
            for root, _, files in os.walk(tmpdir):
                for file in files:
                    if file.endswith(
                        (".py", ".java", ".js", ".ts", ".cpp", ".c", ".cs")):
                        file_path = os.path.join(root, file)
                        rel_display = os.path.relpath(file_path, tmpdir)
                        file_list.append(rel_display)
                        try:
                            with open(file_path,
                                      "r",
                                      encoding="utf-8",
                                      errors="ignore") as f:
                                code = f.read()
                                full_code += f"\n\n# FILE: {file}\n{code}"
                        except:
                            continue

        prompt = f"""
        ë„ˆëŠ” ì‹œë‹ˆì–´ QA ì—”ì§€ë‹ˆì–´ì´ë©°, í˜„ì¬ '{role}' ì—­í• ì„ ë§¡ê³  ìˆë‹¤.
        ì•„ë˜ì— ì œê³µëœ ì†ŒìŠ¤ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ëŠ¥ ë‹¨ìœ„ì˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ë¼.

        ğŸ“Œ ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•íƒœë¡œ ì‘ì„±í•˜ë˜,
        ìš°ì„ ìˆœìœ„ëŠ” ë°˜ë“œì‹œ High / Medium / Low ì¤‘ í•˜ë‚˜ë¡œ ì‘ì„±í•  ê²ƒ:

        | TC ID | ê¸°ëŠ¥ ì„¤ëª… | ì…ë ¥ê°’ | ì˜ˆìƒ ê²°ê³¼ | ìš°ì„ ìˆœìœ„ |
        |-------|-----------|--------|------------|---------|

        ì†ŒìŠ¤ì½”ë“œ:
        {full_code}
        """

        # âœ… [ìœ ì§€] LLM ìš”ì²­ ë¯¸ë¦¬ë³´ê¸°
        top_files = file_list[:30]
        preview_prompt_head = prompt.strip()[:2000]
        with st.expander("ğŸ” LLM ìš”ì²­ ë¯¸ë¦¬ë³´ê¸° (ì „ì†¡ ì „ í™•ì¸)", expanded=True):
            st.markdown(f"**ëª¨ë¸:** `{model}`  |  **ì—­í• :** `{role}`")
            if top_files:
                st.markdown("**ë¶„ì„ ëŒ€ìƒ íŒŒì¼(ì¼ë¶€):**")
                st.code("\n".join(top_files), language="text")
            st.markdown("**í”„ë¡¬í”„íŠ¸ í”„ë¦¬ë·° (ì•ë¶€ë¶„ 2,000ì):**")
            st.code(preview_prompt_head, language="markdown")

        step_status.info("ğŸ›°ï¸ LLM API í˜¸ì¶œ ì¤€ë¹„ ì™„ë£Œâ€¦")

        # âœ… LLM í˜¸ì¶œ
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={"Authorization": f"Bearer {API_KEY}"},
            json={
                "model": model,
                "messages": [{
                    "role": "user",
                    "content": prompt
                }]
            })

        result = response.json()["choices"][0]["message"]["content"]
        st.session_state.llm_result = result

        rows = []
        for line in result.splitlines():
            if "|" in line and "TC" in line:
                parts = [p.strip() for p in line.strip().split("|")[1:-1]]
                if len(parts) == 5:
                    rows.append(parts)

        if rows:
            df = pd.DataFrame(
                rows, columns=["TC ID]()
