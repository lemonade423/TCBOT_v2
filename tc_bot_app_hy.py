import streamlit as st
import os
import zipfile
import tempfile
import pandas as pd
import requests

# --- [ì¶”ê°€ import: ìƒ˜í”Œ ZIP/í”„ë¦¬ë·°ì—ë§Œ ì‚¬ìš©, ê¸°ì¡´ íë¦„ì— ì˜í–¥ ì—†ìŒ] ---
import io
import re
from collections import Counter
from datetime import datetime
from pathlib import Path
# -----------------------------------------------------------------------

# âœ… OpenRouter API KEY (ë³´ì•ˆ ì£¼ì˜!)
API_KEY = "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"

st.set_page_config(page_title="TC-Bot v3", layout="wide")
st.title("ğŸ§ª TC-Bot v3: í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìë™ ìƒì„±ê¸°")

# =========================
# ì¶”ê°€ ê¸°ëŠ¥ 1) ğŸ“¦ ìƒ˜í”Œì½”ë“œ ZIP ë‹¤ìš´ë¡œë“œ
# =========================
def build_sample_project_zip() -> bytes:
    """
    ì—…ë¡œë“œ ì—†ì´ë„ íŒŒì„œ/ë¯¸ë¦¬ë³´ê¸° íë¦„ì„ ì‹œí—˜ ê°€ëŠ¥í•œ
    Python/Java/JavaScript í˜¼í•© ìƒ˜í”Œ í”„ë¡œì íŠ¸ ZIPì„ in-memoryë¡œ ìƒì„±
    """
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, mode="w", compression=zipfile.ZIP_DEFLATED) as z:
        # Python ìƒ˜í”Œ
        z.writestr(
            "sample_project_py/app.py",
            '''"""
ìƒ˜í”Œ íŒŒì´ì¬ ì„œë¹„ìŠ¤
- /health ì—”ë“œí¬ì¸íŠ¸: ìƒíƒœ í™•ì¸
- /sum?a=1&b=2 í•©ê³„ ê³„ì‚°
"""
from flask import Flask, request, jsonify
app = Flask(__name__)

@app.get("/health")
def health():
    return jsonify({"status": "ok"})

@app.get("/sum")
def sum_api():
    try:
        a = float(request.args.get("a", 0))
        b = float(request.args.get("b", "0"))
        return jsonify({"result": a + b})
    except Exception as e:
        return jsonify({"error": str(e)}), 400

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
'''
        )
        z.writestr("sample_project_py/requirements.txt", "flask==3.0.3\n")

        # Java ìƒ˜í”Œ
        z.writestr(
            "sample_project_java/src/main/java/com/example/CalcService.java",
            '''package com.example;

public class CalcService {
    public int add(int a, int b) { return a + b; }
    public int sub(int a, int b) { return a - b; }
    public boolean isEven(int n) { return n % 2 == 0; }
}
'''
        )
        z.writestr(
            "sample_project_java/README.md",
            "# Java ìƒ˜í”Œ\n- ê°„ë‹¨í•œ ì‚¬ì¹™ì—°ì‚°/ì§ìˆ˜íŒë³„ ë©”ì†Œë“œ í¬í•¨"
        )

        # JS ìƒ˜í”Œ
        z.writestr(
            "sample_project_js/index.js",
            '''// ê°„ë‹¨í•œ ì…ë ¥ ê²€ì¦ + í•©ê³„
export function sum(a, b) {
  if (typeof a !== "number" || typeof b !== "number") {
    throw new Error("Invalid input");
  }
  return a + b;
}
'''
        )
        z.writestr(
            "sample_project_js/package.json",
            '''{
  "name": "sample-project-js",
  "version": "1.0.0",
  "type": "module",
  "main": "index.js"
}
'''
        )

        # ì•ˆë‚´ ë¬¸ì„œ
        z.writestr(
            "README.md",
            f"""# TC-Bot ìƒ˜í”Œ ì½”ë“œ ë²ˆë“¤
ì—…ë¡œë“œ ì—†ì´ë„ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ì„ ë°”ë¡œ ì‹œí—˜í•  ìˆ˜ ìˆë„ë¡ ë§Œë“  ì˜ˆì œ ì†ŒìŠ¤ì…ë‹ˆë‹¤.
- Python(Flask) / Java / JavaScript ì˜ˆì œ í¬í•¨
- íŒŒì„œ ê²€ì¦ìš©ìœ¼ë¡œ ë‹¤ì–‘í•œ í™•ì¥ì/ë””ë ‰í† ë¦¬ êµ¬ì¡° ì œê³µ

ìƒì„± ì‹œê°: {datetime.now().isoformat(timespec='seconds')}
"""
        )
    buf.seek(0)
    return buf.read()

with st.container():
    st.subheader("ğŸ“¦ ìƒ˜í”Œì½”ë“œ ë‹¤ìš´ë¡œë“œ (ì—…ë¡œë“œ ì—†ì´ ë°”ë¡œ í…ŒìŠ¤íŠ¸)")
    st.caption("íŒŒì´ì¬/ìë°”/ìë°”ìŠ¤í¬ë¦½íŠ¸ í˜¼í•© ì˜ˆì œ í¬í•¨ Â· íŒŒì„œ/ë¯¸ë¦¬ë³´ê¸° íë¦„ ê²€ì¦ì— ì í•©")
    sample_zip_bytes = build_sample_project_zip()
    st.download_button(
        "â¬‡ï¸ ìƒ˜í”Œì½”ë“œ .zip ë‹¤ìš´ë¡œë“œ",
        data=sample_zip_bytes,
        file_name="tc-bot-sample-code.zip",
        mime="application/zip",
        help="ì˜ˆì œ ì†ŒìŠ¤(zip)ë¥¼ ë‚´ë ¤ë°›ì•„ ë°”ë¡œ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•˜ì„¸ìš”.",
        key="dl_sample_zip",
    )

# âœ… ì‚¬ì´ë“œë°” ì…ë ¥
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    model = st.selectbox("ğŸ¤– ì‚¬ìš©í•  LLM ëª¨ë¸", ["qwen/qwen-max", "mistral"])
    role = st.selectbox("ğŸ‘¤ QA ì—­í• ", ["ê¸°ëŠ¥ QA", "ë³´ì•ˆ QA", "ì„±ëŠ¥ QA"])

# âœ… ì„¸ì…˜ ì´ˆê¸°í™”
if "last_uploaded_file" not in st.session_state:
    st.session_state.last_uploaded_file = None
if "last_model" not in st.session_state:
    st.session_state.last_model = None
if "last_role" not in st.session_state:
    st.session_state.last_role = None
if "llm_result" not in st.session_state:
    st.session_state.llm_result = None
if "parsed_df" not in st.session_state:
    st.session_state.parsed_df = None

# --- [ì¶”ê°€: Auto-Flow Previewìš© ìƒíƒœë§Œ ë³„ë„ keyë¡œ ë³´ê´€] ---
st.session_state.setdefault("preview_stats", None)
st.session_state.setdefault("preview_df", None)
# ----------------------------------------------------------------

uploaded_file = st.file_uploader("ğŸ“‚ ì†ŒìŠ¤ì½”ë“œ zip íŒŒì¼ ì—…ë¡œë“œ", type=["zip"])

def need_llm_call(uploaded_file, model, role):
    # ì´ì „ ì„¸ì…˜ ìƒíƒœì™€ ë¹„êµ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    return (uploaded_file is not None
            and (st.session_state.last_uploaded_file != uploaded_file.name
                 or st.session_state.last_model != model
                 or st.session_state.last_role != role))

# =========================
# ì¶”ê°€ ê¸°ëŠ¥ 2) ğŸ” Auto-Flow Preview
#  - ì—…ë¡œë“œ ZIPì„ LLM í˜¸ì¶œ ì „ì— ë¹ ë¥´ê²Œ ìŠ¤ìº”í•˜ì—¬
#    (íŒŒì¼ ìˆ˜/ì–¸ì–´/í•¨ìˆ˜Â·ì—”ë“œí¬ì¸íŠ¸) ìš”ì•½ + íœ´ë¦¬ìŠ¤í‹± ë¯¸ë¦¬ë³´ê¸° 3ê±´
# =========================
LANG_EXT = {
    ".py": "Python",
    ".java": "Java",
    ".js": "JavaScript",
    ".ts": "TypeScript",
    ".cpp": "C++",
    ".c": "C",
    ".cs": "C#",
}

def extract_functions(file_path: Path, text: str):
    funcs = []
    try:
        if file_path.suffix == ".py":
            funcs += re.findall(r"def\s+([a-zA-Z_]\w*)\s*\(", text)
            # Flask/FastAPI ì—”ë“œí¬ì¸íŠ¸ ê°ì§€
            funcs += re.findall(r"@app\.(?:get|post|put|delete|patch)\(['\"]/([^\)'\"]+)", text)
        elif file_path.suffix == ".java":
            funcs += re.findall(r"(?:public|private|protected)\s+[<>\w\[\]]+\s+([a-zA-Z_]\w*)\s*\(", text)
        elif file_path.suffix in [".js", ".ts"]:
            funcs += re.findall(r"function\s+([a-zA-Z_]\w*)\s*\(", text)
            funcs += re.findall(r"export\s+function\s+([a-zA-Z_]\w*)\s*\(", text)
    except Exception:
        pass
    # ì¤‘ë³µ ì œê±°, ìµœëŒ€ 10ê°œ
    seen, uniq = set(), []
    for f in funcs:
        if f not in seen:
            uniq.append(f); seen.add(f)
    return uniq[:10]

def analyze_source_tree(root_dir: str, role: str):
    exts, file_list, functions = [], [], []
    for r, _, files in os.walk(root_dir):
        for fn in files:
            p = Path(r) / fn
            ext = p.suffix.lower()
            if ext in LANG_EXT:
                file_list.append(str(p))
                exts.append(ext)
                try:
                    with open(p, "r", encoding="utf-8", errors="ignore") as f:
                        txt = f.read()
                    functions.extend([f"{Path(p).name}:{n}" for n in extract_functions(p, txt)])
                except Exception:
                    continue
    lang_counts = Counter(LANG_EXT[e] for e in exts)
    total_files = len(file_list)
    weight = {"ê¸°ëŠ¥ QA": 1.2, "ë³´ì•ˆ QA": 1.1, "ì„±ëŠ¥ QA": 1.0}.get(role, 1.0)
    estimated_cases = max(5, int(len(functions) * 1.5 * weight))
    return {
        "total_files": total_files,
        "lang_counts": lang_counts,
        "top_functions": functions[:10],
        "estimated_cases": estimated_cases
    }

def build_preview_testcases(stats):
    # íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë¯¸ë¦¬ë³´ê¸° 3ê±´
    rows = []
    lang_str = ", ".join([f"{k} {v}ê°œ" for k, v in stats["lang_counts"].most_common()])
    rows.append(["TC-PV-001", "ì–¸ì–´ í˜¼í•© í”„ë¡œì íŠ¸ ë¡œë”©", f"ì–¸ì–´ë¶„í¬: {lang_str}", "ëª¨ë“  íŒŒì¼ íŒŒì‹± ì„±ê³µ", "High"])
    if stats["top_functions"]:
        fn = stats["top_functions"][0]
        rows.append(["TC-PV-002", f"í•µì‹¬ í•¨ìˆ˜/ì—”ë“œí¬ì¸íŠ¸ ë™ì‘ ê²€ì¦({fn})", "ìœ íš¨/ë¬´íš¨ ì…ë ¥ 2ì„¸íŠ¸", "ì •ìƒ/ì—ëŸ¬ ì‘ë‹µ êµ¬ë¶„", "High"])
    else:
        rows.append(["TC-PV-002", "ì—”ë“œí¬ì¸íŠ¸/í•¨ìˆ˜ ë¯¸ê²€ì¶œ ì‹œ ê¸°ë³¸ ë™ì‘", "ê¸°ë³¸ ì‹¤í–‰", "ì—ëŸ¬ ì—†ì´ ì•± ë¶€íŒ…", "Medium"])
    rows.append(["TC-PV-003", "ëŒ€ìƒ ì½”ë“œ ë²”ìœ„ ì»¤ë²„ë¦¬ì§€ ì´ˆê¸° ì ê²€", f"íŒŒì¼ ìˆ˜={stats['total_files']}", "ì£¼ìš” ëª¨ë“ˆë³„ 1ê°œ ì´ìƒ ì¼€ì´ìŠ¤ ì¡´ì¬", "Medium"])
    return pd.DataFrame(rows, columns=["TC ID", "ê¸°ëŠ¥ ì„¤ëª…", "ì…ë ¥ê°’", "ì˜ˆìƒ ê²°ê³¼", "ìš°ì„ ìˆœìœ„"])

# ì—…ë¡œë“œë˜ë©´, LLM í˜¸ì¶œ ì¡°ê±´ê³¼ ìƒê´€ì—†ì´ "ë¯¸ë¦¬ë³´ê¸°"ë§Œ ë¨¼ì € ìˆ˜í–‰ (ê¸°ì¡´ ë¡œì§ì— ì˜í–¥ ì—†ìŒ)
if uploaded_file is not None:
    with tempfile.TemporaryDirectory() as tmpdir_preview:
        try:
            # ì—…ë¡œë“œ ZIP ì„ì‹œ ì €ì¥/ì¶”ì¶œ
            zip_path = os.path.join(tmpdir_preview, uploaded_file.name)
            with open(zip_path, "wb") as f:
                f.write(uploaded_file.read())
            with zipfile.ZipFile(zip_path, "r") as zip_ref:
                zip_ref.extractall(tmpdir_preview)

            # ë¶„ì„ & ë¯¸ë¦¬ë³´ê¸° í‘œ ìƒì„±
            stats = analyze_source_tree(tmpdir_preview, role)
            st.session_state.preview_stats = stats
            st.session_state.preview_df = build_preview_testcases(stats)

            # UI í‘œì‹œ
            with st.expander("ğŸ” Auto-Flow Preview (LLM í˜¸ì¶œ ì „ ë¹ ë¥¸ ìš”ì•½)", expanded=True):
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("íŒŒì¼ ìˆ˜", f"{stats['total_files']}ê°œ")
                lang_top = stats["lang_counts"].most_common(1)[0][0] if stats["lang_counts"] else "-"
                c2.metric("ì£¼ìš” ì–¸ì–´", lang_top)
                c3.metric("ì˜ˆìƒ TC ìˆ˜", stats["estimated_cases"])
                c4.metric("í•¨ìˆ˜/ì—”ë“œí¬ì¸íŠ¸ ê°ì§€", f"{len(stats['top_functions'])}ê°œ")
                st.caption("â€» ì•„ë˜ ë¯¸ë¦¬ë³´ê¸°ëŠ” íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ì…ë‹ˆë‹¤. ìµœì¢… ê²°ê³¼ëŠ” LLM ìƒì„± í›„ ê°±ì‹ ë©ë‹ˆë‹¤.")
                st.dataframe(st.session_state.preview_df, use_container_width=True)

        except Exception as e:
            # ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨í•´ë„ LLM ë³¸ íë¦„ì€ ê·¸ëŒ€ë¡œ ì§„í–‰ ê°€ëŠ¥í•˜ë„ë¡ ê²½ê³ ë§Œ í‘œê¸°
            st.warning(f"Auto-Flow Preview ì¤‘ ê²½ê³ : {e}")

# =========================
# (ì•„ë˜ë¶€í„°ëŠ” ì†ŒìŠ¤1ì˜ ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ)
# =========================

# âœ… LLM í˜¸ì¶œ ì¡°ê±´ í™•ì¸
if uploaded_file and need_llm_call(uploaded_file, model, role):
    with st.spinner("ğŸ” LLM í˜¸ì¶œ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):
        with tempfile.TemporaryDirectory() as tmpdir:
            zip_path = os.path.join(tmpdir, uploaded_file.name)
            with open(zip_path, "wb") as f:
                f.write(uploaded_file.read())

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(tmpdir)

            full_code = ""
            for root, _, files in os.walk(tmpdir):
                for file in files:
                    if file.endswith(
                        (".py", ".java", ".js", ".ts", ".cpp", ".c", ".cs")):
                        file_path = os.path.join(root, file)
                        try:
                            with open(file_path,
                                      "r",
                                      encoding="utf-8",
                                      errors="ignore") as f:
                                code = f.read()
                                full_code += f"\n\n# FILE: {file}\n{code}"
                        except:
                            continue

        # âœ… Prompt êµ¬ì„±
        prompt = f"""
        ë„ˆëŠ” ì‹œë‹ˆì–´ QA ì—”ì§€ë‹ˆì–´ì´ë©°, í˜„ì¬ '{role}' ì—­í• ì„ ë§¡ê³  ìˆë‹¤.
        ì•„ë˜ì— ì œê³µëœ ì†ŒìŠ¤ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ëŠ¥ ë‹¨ìœ„ì˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ë¼.

        ğŸ“Œ ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•íƒœë¡œ ì‘ì„±í•˜ë˜,
        ìš°ì„ ìˆœìœ„ëŠ” ë°˜ë“œì‹œ High / Medium / Low ì¤‘ í•˜ë‚˜ë¡œ ì‘ì„±í•  ê²ƒ:

        | TC ID | ê¸°ëŠ¥ ì„¤ëª… | ì…ë ¥ê°’ | ì˜ˆìƒ ê²°ê³¼ | ìš°ì„ ìˆœìœ„ |
        |-------|-----------|--------|------------|---------|

        ì†ŒìŠ¤ì½”ë“œ:
        {full_code}
        """

        # âœ… LLM í˜¸ì¶œ
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={"Authorization": f"Bearer {API_KEY}"},
            json={
                "model": model,
                "messages": [{
                    "role": "user",
                    "content": prompt
                }]
            })

        result = response.json()["choices"][0]["message"]["content"]
        st.session_state.llm_result = result

        # âœ… ê²°ê³¼ íŒŒì‹±
        rows = []
        for line in result.splitlines():
            if "|" in line and "TC" in line:
                parts = [p.strip() for p in line.strip().split("|")[1:-1]]
                if len(parts) == 5:
                    rows.append(parts)

        if rows:
            df = pd.DataFrame(
                rows, columns=["TC ID", "ê¸°ëŠ¥ ì„¤ëª…", "ì…ë ¥ê°’", "ì˜ˆìƒ ê²°ê³¼", "ìš°ì„ ìˆœìœ„"])
            st.session_state.parsed_df = df

        # âœ… ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state.last_uploaded_file = uploaded_file.name
        st.session_state.last_model = model
        st.session_state.last_role = role

# âœ… ê²°ê³¼ ë Œë”ë§
if st.session_state.llm_result:
    st.success("âœ… í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì™„ë£Œ!")
    st.markdown("## ğŸ“‹ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤")
    st.markdown(st.session_state.llm_result)

# âœ… ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
if st.session_state.parsed_df is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
        st.session_state.parsed_df.to_excel(tmp.name, index=False)
        tmp.seek(0)
        st.download_button("â¬‡ï¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                           data=tmp.read(),
                           file_name="í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤.xlsx")
